{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Define imports and constants**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport cv2\nimport tensorflow as tf\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.layers import *\nfrom tensorflow.keras.callbacks import *\nfrom keras.models import Model\nfrom keras.utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras import backend as K\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\nprint(training.head(10))","execution_count":2,"outputs":[{"output_type":"stream","text":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n5  ISIC_0074311  IP_2950485  female        40.0               lower extremity   \n6  ISIC_0074542  IP_4698288    male        25.0               lower extremity   \n7  ISIC_0075663  IP_6017204  female        35.0                         torso   \n8  ISIC_0075914  IP_7622888    male        30.0                         torso   \n9  ISIC_0076262  IP_5075533  female        50.0               lower extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  \n5   unknown           benign       0  \n6   unknown           benign       0  \n7   unknown           benign       0  \n8   unknown           benign       0  \n9   unknown           benign       0  \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training[\"target\"].value_counts())","execution_count":3,"outputs":[{"output_type":"stream","text":"0    32542\n1      584\nName: target, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_aug = ImageDataGenerator(rescale=1./255,\n                     rotation_range=70,\n                     width_shift_range=0.3, \n                     height_shift_range=0.3,\n                     shear_range=0.1,\n                     channel_shift_range=20,\n                     horizontal_flip=True,\n                     vertical_flip=True)\n\nval_aug = ImageDataGenerator(rescale=1./255)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/qubvel/efficientnet","execution_count":6,"outputs":[{"output_type":"stream","text":"Collecting git+https://github.com/qubvel/efficientnet\n  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-pu73odoo\n  Running command git clone -q https://github.com/qubvel/efficientnet /tmp/pip-req-build-pu73odoo\nCollecting keras_applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 2.3 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.16.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.18.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\nRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.4.1)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.2.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.4)\nRequirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (5.4.1)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.8.0)\nRequirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.14.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.2.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\nBuilding wheels for collected packages: efficientnet\n  Building wheel for efficientnet (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-1.1.0-py3-none-any.whl size=18397 sha256=34edd80622064280ce9a813b36dcd50b29dba095cbe21c1c8126c8aa5c376ae7\n  Stored in directory: /tmp/pip-ephem-wheel-cache-5zvw1yhd/wheels/11/69/85/814d64d694c96db0eef17b718042d644a1e54f113920481920\nSuccessfully built efficientnet\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.0 keras-applications-1.0.8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import efficientnet.keras as efn ","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=5e-4)\n# opt = keras.optimizers.Adamax(learning_rate=1e-5)\n# opt = keras.optimizers.Adagrad(learning_rate=1e-5)\nloss = keras.losses.BinaryCrossentropy(label_smoothing = 0.02)\n# loss = focal_loss()\nauc = keras.metrics.AUC()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lr_callback():   \n    def lrfn(epoch, rate):\n        if epoch < 3:\n            lr = 1e-4           \n        else:\n            lr = rate*0.75            \n        return lr\n\n    callback = LearningRateScheduler(lrfn, verbose=True)\n    return callback","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Begin Training Cycle**"},{"metadata":{"trusted":true},"cell_type":"code","source":"effnetb6 = efn.EfficientNetB6(\n            include_top=False,\n            weights=\"imagenet\",\n            input_shape=(256,256,3))\nflat0 = Flatten()(effnetb6.output)\ndense0 = Dense(1, activation=\"sigmoid\")(flat0)\nmodel0 = Model(effnetb6.input, dense0)\n\n# effnetb7 = efn.EfficientNetB7(\n#             include_top=False,\n#             weights=\"imagenet\",\n#             input_shape=(256,256,3))\n# flat1 = Flatten()(effnetb7.output)\n# dense1 = Dense(1, activation=\"sigmoid\")(flat1)\n# model1 = Model(effnetb7.input, dense1)\n    \nmodel0.compile(loss=loss, metrics=auc, optimizer=opt)\n# model1.compile(loss=loss, metrics=auc, optimizer=opt)","execution_count":10,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b6_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n165527552/165527152 [==============================] - 4s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"histories = []\n# testing = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\n# testing[\"image_name\"] = \"../input/images-siim-512x512/test/test_512x512/\" + testing[\"image_name\"].astype(str) + \".jpg\"\n# testing.head()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = np.load('../input/kernel74cf188148/effnet256.npz')[\"images\"]\nprint(test_images.shape)","execution_count":12,"outputs":[{"output_type":"stream","text":"(10982, 256, 256, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model):\n    predictions = np.empty(0)\n    k = test_images.shape[0]\n    i = 0\n    p_bar = tqdm(total=k)\n    while True:\n        images=[]\n        for j in range(128):\n            p_bar.update(1)\n            if(i>=k):\n                pred=model.predict(np.array(images))\n                pred=np.squeeze(pred)\n                predictions = np.concatenate((predictions, pred))\n                print(predictions.shape)\n                return predictions\n            images.append(test_images[i].astype(np.float32)/255.) \n            i+=1\n            \n        pred=model.predict(np.array(images))\n        pred=np.squeeze(pred)\n        predictions = np.concatenate((predictions, pred))\n        del images\n        gc.collect()","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 0\nt","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"t += 1\nt","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"1"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = training[training[\"target\"]==1]\nb = training[training[\"target\"]==0].sample(2200)\ndf = pd.concat([m,b])\ndf.reset_index(inplace=True)\ndf.drop(labels=[\"index\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"diagnosis\", \"benign_malignant\"], axis=1, inplace=True)\ndf[\"image_name\"] = \"../input/images-siim-512x512/train/train_512x512/\" + df[\"image_name\"].astype(str) + \".jpg\"\n    ","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, valX, trainY, valY = train_test_split(\ndf[\"image_name\"], \ndf[\"target\"],\ntest_size = 0.2, \nrandom_state = 888)\n\ntrain = list(zip(trainX, trainY))\ntrain = pd.DataFrame(train, columns = [\"images\", \"target\"])\nval = list(zip(valX, valY))\nval = pd.DataFrame(val, columns = [\"images\", \"target\"])\n\ntrain_gen = train_aug.flow_from_dataframe(train, x_col=\"images\", y_col=\"target\", batch_size = 16, target_size=(256,256),shuffle = True, class_mode=\"raw\")\nval_gen = val_aug.flow_from_dataframe(val, x_col=\"images\", y_col=\"target\", batch_size = 16, target_size=(256,256),shuffle = False, class_mode=\"raw\")","execution_count":26,"outputs":[{"output_type":"stream","text":"Found 2227 validated image filenames.\nFound 557 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model0.fit_generator(train_gen,\n    steps_per_epoch = trainX.shape[0] // 16,\n    epochs = 1, \n    validation_data = val_gen,\n    validation_steps = valX.shape[0] // 16\n)\n\nhistories.append(history)","execution_count":41,"outputs":[{"output_type":"stream","text":"139/139 [==============================] - 102s 735ms/step - loss: 0.4426 - auc: 0.8373 - val_loss: 0.4742 - val_auc: 0.8384\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"t += 1","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = predict(model0)            \nresults = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\nresults['target'] = predictions\nresults.to_csv(f\"effnet_{t}.csv\", header=True, index=False)\n# model0.save(f\"effnet_{t}.h5\")","execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10982.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"102e7afe3755429389cfc490dad567d6"}},"metadata":{}},{"output_type":"stream","text":"(10982,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del trainX, trainY, valX, valY, train_gen, val_gen, train, val\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.remove(\"effnet4.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model0\ngc.collect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for t in range(6):\n    m = training[training[\"target\"]==1]\n    b = training[training[\"target\"]==0].sample(2000)\n    df = pd.concat([m,b])\n    df.reset_index(inplace=True)\n    df.drop(labels=[\"index\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"diagnosis\", \"benign_malignant\"], axis=1, inplace=True)\n    df[\"image_name\"] = \"../input/images-siim-512x512/train/train_512x512/\" + df[\"image_name\"].astype(str) + \".jpg\"\n    \n    trainX, valX, trainY, valY = train_test_split(\n    df[\"image_name\"], \n    df[\"target\"],\n    test_size = 0.2, \n    random_state = 888)\n    \n    train = list(zip(trainX, trainY))\n    train = pd.DataFrame(train, columns = [\"images\", \"target\"])\n    val = list(zip(valX, valY))\n    val = pd.DataFrame(val, columns = [\"images\", \"target\"])\n    \n    train_gen = train_aug.flow_from_dataframe(train, x_col=\"images\", y_col=\"target\", batch_size = 16, target_size=(256,256),shuffle = True, class_mode=\"raw\")\n    val_gen = val_aug.flow_from_dataframe(val, x_col=\"images\", y_col=\"target\", batch_size = 16, target_size=(256,256),shuffle = False, class_mode=\"raw\")\n    \n    if (t < 3):\n        history = model0.fit_generator(\n        train_gen,\n        steps_per_epoch = trainX.shape[0] // 8,\n        epochs = 4, \n        validation_data = val_gen,\n        validation_steps = valX.shape[0] // 8)\n        histories.append(history)\n        \n        predictions = predict(model0)\n            \n        results = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\n        results['target'] = predictions\n        results.to_csv(f\"effnet{t}.csv\", header=True, index=False)\n        model0.save(f\"effnet{t}\")    \n    else:\n        history = model1.fit_generator(\n        train_gen,\n        steps_per_epoch = trainX.shape[0] // 8,\n        epochs = 4, \n        validation_data = val_gen,\n        validation_steps = valX.shape[0] // 8)\n        histories.append(history)\n        \n        predictions = predict(model0)\n        predictions = []\n        for img in tqdm(testing[\"image_name\"]): \n            img = cv2.imread(str(img))            \n            img = cv2.resize(img, (256,256))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = img.astype(np.float32)/255.\n            img=np.reshape(img,(1,256,256,3))       \n            pred=model1.predict(img)\n            predictions.append(pred[0][0])\n            del img\n            gc.collect()\n            \n        results = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\n        results['target'] = predictions\n        results.to_csv(f\"effnet{t}.csv\", header=True, index=False)\n        model1.save(f\"effnet{t}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_num = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# m = training[training[\"target\"]==1]\n# b = training[training[\"target\"]==0].sample(2000)\n# df = pd.concat([m,b])\n# df.reset_index(inplace=True)\n# df.drop(labels=[\"index\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"diagnosis\", \"benign_malignant\"], axis=1, inplace=True)\n# df[\"image_name\"] = \"../input/images-siim-512x512/train/train_512x512/\" + df[\"image_name\"].astype(str) + \".jpg\"\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imgs = []\n# labels = []\n# for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n#     img = cv2.imread(str(row[\"image_name\"]))\n    \n#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#     imgs.append(img)\n#     labels.append(row[\"target\"])\n# imgs = np.array(imgs)\n# labels = np.array(labels)\n# print(imgs.shape)\n# print(labels.shape)\n# del m, b, df\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainX, valX, trainY, valY = train_test_split(imgs, labels, test_size=0.2, random_state=888)\n# print(trainX.shape)\n# print(valX.shape)\n# print(trainY.shape)\n# print(valY.shape)\n# lenT = trainX.shape[0]\n# lenV = valX.shape[0]\n# del imgs, labels\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_gen = train_aug.flow(trainX, trainY, batch_size = 4, shuffle = True)\n# val_gen = val_aug.flow(valX, valY, batch_size = 4, shuffle = False)\n# del trainX, valX, trainY, valY\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# early_stop = EarlyStopping(monitor='val_loss', patience=2)\n# checkpoint = ModelCheckpoint(\"{val_loss:.3f}-{epoch:02d}.hdf5\",monitor = 'val_loss',verbose = 1,save_best_only = True,mode = 'min')\n\n# callbacks = [early_stop, checkpoint, lr_callback()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def eff():\n#     if(model_num == 0):\n#         return efn.EfficientNetB6(\n#             include_top=False,\n#             weights=\"imagenet\",\n#             input_shape=(512,512,3)\n#         )\n#     else: \n#         return efn.EfficientNetB7(\n#             include_top=False,\n#             weights=\"imagenet\",\n#             input_shape=(512,512,3)\n#         )\n# # effnet.trainable=False\n# effnet=eff()\n# flat = Flatten()(effnet.output)\n# # gap = GlobalAveragePooling2D()(effnet.output)\n# # final = Dropout(0.4)(flat)#\n# # final = Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(final)\n# # final = Dropout(0.4)(final)\n# dropout = Dropout(0.2)(flat)\n# final = Dense(1, activation=\"sigmoid\")(dropout)\n# model = Model(effnet.input,final)\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compile(loss=loss, metrics=auc, optimizer=opt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit_generator(\n#     train_gen,\n#     steps_per_epoch = lenT // 4,\n#     epochs = 8, \n#     validation_data = val_gen,\n#     validation_steps = lenV // 4,\n#     callbacks = callbacks\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"DONE\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save('effnet2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist = pd.DataFrame(history.history)\n# hist['epoch'] = history.epoch\n\n# plt.figure()\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.plot(hist['epoch'], hist['loss'], label='Train Error')\n# plt.plot(hist['epoch'], hist['val_loss'], label='Val Error')\n# plt.ylim([0, 1])\n# plt.legend()\n\n# plt.figure()\n# plt.xlabel('Epoch')\n# plt.ylabel('accuracy')\n# plt.plot(hist['epoch'], hist['auc'], label='Train Acc')\n# plt.plot(hist['epoch'], hist['val_auc'], label='Val Acc')\n# plt.ylim([0, 1])\n# plt.legend()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del train_gen, val_gen\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del effnet, flat, dropout, final, model, hist, history\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for layer in effnet.layers[745:]:\n#    layer.trainable = True\n# for i, layer in enumerate(effnet.layers):\n#    print(i, layer.name, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now there's several million more trainable parameters."},{"metadata":{},"cell_type":"markdown","source":"I don't use AUC in this demo, but to implement it all you need to do is to set metrics=\\[auc\\]"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=opt)\n\n# history = model.fit_generator(\n#     train_gen,\n#     steps_per_epoch = trainX.shape[0] // 16,\n#     epochs = 10, \n#     validation_data = val_gen,\n#     validation_steps = valX.shape[0] // 16,\n#     callbacks = callbacks\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del trainX, trainY, valX, valY\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now for predicting. I print out the first 50 predictions just to make sure things are going right."},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_images = np.load('../input/siimisic-melanoma-resized-images/x_test_224.npy')\n# print(test_images.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def predict(num, model):\n#     predictions = np.empty(0)\n#     k = test_images.shape[0]\n#     i = 0\n#     p_bar = tqdm(total=test_images.shape[0])\n#     while True:\n#         images=[]\n#         for j in range(32):\n#             p_bar.update(1)\n#             if(i>=k):\n#                 pred=model.predict(np.array(images))\n#                 pred=np.squeeze(pred)\n#                 predictions = np.concatenate((predictions, pred))\n#                 print(predictions.shape)\n#                 return predictions\n#             images.append(test_images[i].astype(np.float32)/255.) \n#             i+=1\n            \n#         pred=model.predict(np.array(images))\n#         pred=np.squeeze(pred)\n#         predictions = np.concatenate((predictions, pred))\n#         del images\n#         gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def predict1():\n#     predictions = np.empty(0)\n#     k = test_images.shape[0]\n#     i = 0\n#     p_bar = tqdm(total=test_images.shape[0])\n#     while True:\n#         images=[]\n#         for j in range(64):\n#             p_bar.update(1)\n#             if(i>=k):\n#                 pred=model1.predict(np.array(images))\n#                 pred=np.squeeze(pred)\n#                 predictions = np.concatenate((predictions, pred))\n#                 print(predictions.shape)\n#                 return predictions\n#             images.append(test_images[i].astype(np.float32)/255.) \n#             i+=1\n            \n#         pred=model1.predict(np.array(images))\n#         pred=np.squeeze(pred)\n#         predictions = np.concatenate((predictions, pred))\n#         del images\n#         gc.collect()\n        \n# predictions1 = predict1()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(predictions[:50])\n# print(predictions1[:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from scipy.special import logit, expit\n# predictions = expit((0.5* logit(predictions) + (0.5 * logit(predictions1))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds = 0.5*(predictions + predictions1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# results = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\n# results['target'] = preds\n# results.to_csv('effnet3.csv', header=True, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}